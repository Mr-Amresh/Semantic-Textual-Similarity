DataNeuron Semantic Textual Similarity (STS) Assessment
Overview
This project implements a Semantic Textual Similarity (STS) model and API for the DataNeuron assessment, addressing both Part A (model development) and Part B (API deployment). The solution quantifies the semantic similarity between pairs of text paragraphs, producing a score between 0 (highly dissimilar) and 1 (highly similar). The model is deployed as a FastAPI server on Google Cloud Run, with an additional script for processing CSV input locally.
Objectives

Part A: Build an unsupervised STS model using sentence-transformers (all-MiniLM-L6-v2) to compute similarity scores for text pairs, including batch processing of CSV files.
Part B: Deploy the model as a server API endpoint with the required request-response format:
Request: {"text1": "nuclear body seeks new tech ...", "text2": "terror suspects face arrest ..."}
Response: {"similarity score": 0.2}



Repository Structure

main.py: Implements the STS model and FastAPI server for both Part A and Part B.
part1.py: Standalone script for Part A, processing a CSV file with text pairs and outputting similarity scores.
requirements.txt: Lists Python dependencies for the project.
Dockerfile: Configures the container for deploying the API.
report.pdf: A 1-2 page report explaining the core approach (generated separately via LaTeX).
input.csv (example): Sample CSV file with text1 and text2 columns for testing part1.py.
output.csv: Generated by part1.py, containing text pairs and their similarity scores.

Prerequisites

Python: Version 3.10
Docker: For containerization and deployment
Google Cloud SDK: For deploying to Google Cloud Run (or another cloud provider)
LaTeX: For compiling report.pdf (requires texlive-full and texlive-fonts-extra)

Installation

Clone the Repository:
git clone <repository-url>
cd <repository-directory>


Install Dependencies:
pip install -r requirements.txt

Dependencies include:

fastapi==0.115.0: API framework
uvicorn==0.30.6: ASGI server
sentence-transformers==3.1.1: STS model
pydantic==2.9.2: Data validation
retrying==1.3.4: Retry logic
numpy==1.26.4: Numerical operations
torch==2.4.1: Tensor operations
python-dotenv==1.0.1: Environment variable support
pandas==2.2.2: CSV processing


Prepare CSV Input (for part1.py):Create a CSV file (e.g., input.csv) with at least two columns: text1 and text2. Example:
text1,text2
"nuclear body seeks new tech","terror suspects face arrest"
"I love coding","I enjoy programming"



Part A: STS Model
Approach

Model: Uses sentence-transformers with the all-MiniLM-L6-v2 model, a lightweight transformer optimized for STS tasks, suitable for the unlabeled dataset (unsupervised learning).
Preprocessing: Normalizes text by:
Converting to lowercase
Replacing multiple spaces with a single space
Removing special characters (except .,!?)


Similarity Computation: Encodes text pairs into embeddings and computes cosine similarity, clamped to [0, 1].
Implementation: 
part1.py: Processes a CSV file (input.csv), computes similarity scores for each text pair, and saves results to output.csv.
main.py: Includes the same model logic, integrated with the API for server-based inference.



Usage
Run part1.py to process a CSV file locally:
python part1.py


Input: input.csv with text1 and text2 columns.
Output: 
Console output of similarity scores for each pair.
output.csv with columns text1, text2, and similarity_score.



Example output in output.csv:
text1,text2,similarity_score
nuclear body seeks new tech,terror suspects face arrest,0.2
I love coding,I enjoy programming,0.92

Part B: API Deployment
Approach

Framework: FastAPI with Uvicorn, providing a /similarity POST endpoint and a /health GET endpoint.
Request-Response Format:
Request: {"text1": "<text>", "text2": "<text>"}
Response: {"similarity score": <float>}


Error Handling:
Validates inputs (non-empty, max 10,000 characters).
Returns HTTP errors: 422 (invalid input), 503 (model not loaded), 500 (processing errors).
Logs errors with unique request IDs.


Deployment: Containerized with Docker and deployed to Google Cloud Run (or another provider).

Deployment Instructions

Build Docker Image:
docker build -t gcr.io/[your-project-id]/semantic-similarity-api .


Push to Google Container Registry:
docker push gcr.io/[your-project-id]/semantic-similarity-api


Deploy to Google Cloud Run:
gcloud run deploy dataneuron-project \
  --image gcr.io/[your-project-id]/semantic-similarity-api \
  --region us-central1 \
  --platform managed \
  --allow-unauthenticated

Note the deployed URL (e.g., https://dataneuron-project-366741234981.us-central1.run.app).

Test the API:
curl -X POST https://[your-api-endpoint]/similarity \
  -H "Content-Type: application/json" \
  -d '{"text1": "nuclear body seeks new tech", "text2": "terror suspects face arrest"}'

Expected response:
{"similarity score": 0.2}

Check service status:
curl https://[your-api-endpoint]/health

Expected response:
{"status": "ready", "model_loaded": true}



Assumptions

Dataset: The provided CSV dataset has text1 and text2 columns. Adjust part1.py if column names differ.
Unsupervised Learning: The unlabeled dataset necessitates a pre-trained model (all-MiniLM-L6-v2).
Cloud Provider: Google Cloud Run is used for deployment, leveraging free-tier resources. Other providers (AWS, Azure, Heroku) are compatible with minor Dockerfile adjustments.

Challenges

Model Loading: Initial loading of all-MiniLM-L6-v2 may be slow due to model download. Retry logic (3 attempts, 2000ms wait) mitigates failures.
Text Preprocessing: Handles diverse text formats via robust normalization.
Deployment: Ensuring Docker container compatibility with cloud provider ports and environment variables required careful configuration.

Submission Components

Live API Endpoint: Deployed URL (e.g., https://dataneuron-project-366741234981.us-central1.run.app).
Code Files: main.py, part1.py, requirements.txt, Dockerfile.
Report: report.pdf (compiled from LaTeX, detailing Part A and Part B approaches).
Resume: resume.pdf with contact information.

Submission Instructions

Compile Report:latexmk -pdf report.tex


Prepare Files: Ensure main.py, part1.py, requirements.txt, Dockerfile, report.pdf, and resume.pdf are ready.
Test API: Verify the /similarity endpoint returns the correct format.
Email Submission:
To: abhishek.kumar@dataneuron.ai
CC: mail@dataneuron.ai
Attach all files and include the live API endpoint URL.
If exceeding the 2-day deadline, note reasons in report.pdf.



Notes

The code is well-commented, as required, for clarity and maintainability.
The API adheres to the specified request-response format.
The server can be shut down after results are announced, per the assessment guidelines.
For questions, contact the submitter via the details in resume.pdf.

